---
layout: post
title: "The FIFO-controlled, text-to-speech narrator"
tags:
  - unix
  - text to speech
  - sox
  - audio
  - i3
  - command line
published: true
---

{% include JB/setup %}

I'm very proud to be married to the amazing modern dance choreographer and
educator [Renay Aumiller][renay-aumiller]. From time to time, Renay and I
collaborate to produce works of modern dance accompanied by original music. Most
recently, we created a piece called _By Chance_ that involves feeding
suggestions from the audience into a web application that I wrote to produce a
randomly generated series of short dance vignettes.

This piece was originally called _Out of the Blue_ because we first performed it
in a room in a warehouse space with dark blue walls. In [a previous blog
post][out-of-the-blue], I talked about my creative process as I was writing /
generating the music, and I shared some excerpts.

An interesting aspect of the piece that I haven't touched on yet is that it
features narration audio that I generated by using [text-to-speech][tts-wiki]
synthesis. Renay's idea was that she would converse with a robotic-sounding
narrator while she performed, which would both highlight the relationship
between humans and computers and add a little bit of humor to the performance.
To make the pace of the conversation sound more natural, I would cue each
portion of dialog from my laptop.

# `say`

I had used the `say` command in the past to generate text-to-speech audio. The
`say` that comes with macOS is great. But I've been developing in an Ubuntu
environment for several years now, and I was curious to explore the
text-to-speech options available for Linux.

A while back, I installed some audio package (I forget which one) via `apt` and
unbeknownst to me, one of the package's dependencies was [GNUstep], a software
bundle that provides a `say` command, among other things.

I gave GNUstep's `say` a try, and the results were underwhelming compared to the
Apple version:

{% highlight bash %}
say "I am a terrible speech synthesizer"
{% endhighlight %}

**TODO: See if I can record a wav of the output and embed an audio player into
the page.**

**Maybe I could use an HTML5 `<audio src="..."></audio>` element?**

It just didn't sound natural enough. I think it's wonderful that the Free
Software Foundation implemented an OSS replacement for the macOS `say` command,
but in a time where children grow up talking to natural-sounding TTS
personalities like Siri and Alexa, GNUstep's `say` comes off as sounding robotic
and corny by comparison.

# Google Text-to-Speech

After looking around for a while for other options, I saw that Google Cloud has
a [Text-to-Speech][google-tts] product. The quality is excellent, but it is a
paid product that requires a Google Cloud account if you want to use the
Text-to-Speech API directly.

It turns out, however, [Google Translate][google-translate] uses the same
Text-to-Speech engine (albeit with less options), and you can use it out of the
box with much less ceremony (and for free, to boot).

* Text-to-speech narrator
  * The best solution I found was the Google Text-to-Speech service
    * To use the Google Text-to-Speech service directly requires a Google Cloud
      Services account, but it turns out that you can use it with less ceremony
      by hitting the free Google Translate API
    * There are multiple command-line tools that do this out of the box with no
      setup
    * The one I use is https://github.com/desbma/GoogleSpeech
      * demo audio player playing the output of `google_speech -l en-uk "i'm a
        good speech synthesizer"`
  * Code example of looping through all the files in a directory, reading line
    by line, and piping each line to `google_speech`:

{% highlight bash %}
find "$narration_dir" | sort | tail -n+2 | while read filename; do
  cat $filename | while read line; do
    google_speech $gs_opts "$line"
  done
done
{% endhighlight %}

* FIFO (mkfifo, etc.)
  * Demo gif using `file example-fifo`, `cat example-fifo`
  * `fifo-narrator` script
    * creates the FIFO
    * waits for "bangs" to arrive on the FIFO, and those "bangs" trigger one
      script file to be narrated
      * timing depends on live performance, so this allows me to control when to
        proceed to the next script
    * i3 keybinding that puts a "bang" onto the FIFO

* Performance #1 (January 2019) was a smash success

* Performance #2 (November 2019) was, unfortunately, ruined by technical
  difficulties
  * Partway through the narration, the narration just stopped working. I
    switched over to my terminal and was presented with a long Python
    stacktrace. Someone in the crowd went "hey, that's Python!" We had to
    stumble onward without the narrator. Renay was furious with me.
  * I hadn't thought about the fact that you need to have access to the Internet
    in order to use the Google Text-to-Speech.
  * Incidentally, it turns out that the google_speech CLI tool works offline by
    caching the audio synthesized from text input that you've handed to it
    before.
    * Performance #1 had (luckily) gone off without a hitch despite my laptop
      not being connected to the internet at the time. The text-to-speech audio
      was being played back from the cache from when we had rehearsed at home.
    * Somehow, during performance #2, I think the cache failed. (Maybe it was
      a TTL cache and it just happened to expire at the worst possible time?
      Who knows?)
  * It became clear that our performance should not depend on the reliability of
    a network connection or the availability of the Google Text-to-Speech
    service.
  * A better approach would be to pre-record the text-to-speech narration and
    simply play it back during the performance. I could use the same FIFO setup
    to cue moving from each audio file to the next.

* Rough calculation of the pauses between utterances in each script file, based
  on the number of consecutive blank lines.

* SoX
  * man page: "Sound eXchange, the Swiss Army knife of audio manipulation"
  * reads and writes audio files
  * actually does a lot more than that, and I've barely scratched the surface of
    what it can do
    * maybe use some of the examples in the man page, which look interesting
  * I'm using it for two things:
    * generate wav files for specific durations of silence
      * `sox -n -r 24k -c 1 "$part_filename" trim 0.0 "$duration"`
    * stitch together TTS mp3s padded by the silent wav files to add pauses
      * `sox $(ls $parts_dir/*) "$mp3_filename"`

# Comments?

Reply to [this tweet][tweet] with any comments, questions, etc.!

[tweet]: https://twitter.com/dave_yarwood/status/FIXME

[renay-aumiller]: https://www.radances.com
[out-of-the-blue]: {% post_url 2019-07-15-out-of-the-blue %}
[tts-wiki]: https://en.wikipedia.org/wiki/Speech_synthesis
[GNUstep]: http://wiki.gnustep.org/index.php/User_FAQ#What_is_GNUstep.3F
[google-tts]: https://cloud.google.com/text-to-speech/
[google-translate]: https://translate.google.com/
